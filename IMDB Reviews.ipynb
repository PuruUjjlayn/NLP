{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "_WtOyul4wbDH",
   "metadata": {
    "id": "_WtOyul4wbDH"
   },
   "source": [
    "# `IMBD` Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ce9b931",
   "metadata": {
    "id": "3ce9b931"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e854097",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "936f56e6",
   "metadata": {
    "id": "936f56e6"
   },
   "outputs": [],
   "source": [
    "temp_df = pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9db1830b",
   "metadata": {
    "id": "9db1830b"
   },
   "outputs": [],
   "source": [
    "df = temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f794ceb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4f794ceb",
    "outputId": "1d1af5e7-d31f-4b30-b5cf-0de96483e95e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c31fb116",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "c31fb116",
    "outputId": "6e1f4c4d-2e5d-49f4-daf1-ef78ec801afb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2TJHxWKYn0L8",
   "metadata": {
    "id": "2TJHxWKYn0L8"
   },
   "source": [
    "### There are html tags in the data set of we have to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18525cb6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "18525cb6",
    "outputId": "1ad26382-e06d-4d0e-9c5a-0ef439187e10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oAp32kQ1n657",
   "metadata": {
    "id": "oAp32kQ1n657"
   },
   "source": [
    "### Data set is a `balanced data set` so we are good to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f207966e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f207966e",
    "outputId": "bda10a15-d4ee-4192-8e9d-c381fba860a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2qAIsPnGoB5W",
   "metadata": {
    "id": "2qAIsPnGoB5W"
   },
   "source": [
    "### There is no null value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea02910b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ea02910b",
    "outputId": "0b72f25f-ea25-4302-f7c9-e31255098ee0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i15PA9vtoFSF",
   "metadata": {
    "id": "i15PA9vtoFSF"
   },
   "source": [
    "### There are some dublicate reviews. So drop these dubplicate reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2254cc43",
   "metadata": {
    "id": "2254cc43"
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bbdbf38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8bbdbf38",
    "outputId": "31d59d30-86c4-481d-bd75-5a19d519f43a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71UFAn6Fwzcs",
   "metadata": {
    "id": "71UFAn6Fwzcs"
   },
   "source": [
    "### `Remove tags`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecb881b9",
   "metadata": {
    "id": "ecb881b9"
   },
   "outputs": [],
   "source": [
    "def remove_tags(raw_text):\n",
    "    cleaned_text = re.sub(re.compile('<.*?>'), '', raw_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "670ecc96",
   "metadata": {
    "id": "670ecc96"
   },
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b21551de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "b21551de",
    "outputId": "a18dd790-d92c-41f8-c82a-d51edee017c7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49582 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. The filming tec...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[49582 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4nZEBU5Mw4ao",
   "metadata": {
    "id": "4nZEBU5Mw4ao"
   },
   "source": [
    "### Lowecase each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e03f81e",
   "metadata": {
    "id": "1e03f81e"
   },
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plVwY2rBo_s5",
   "metadata": {
    "id": "plVwY2rBo_s5"
   },
   "source": [
    "### Chat word teartment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "wkh32O7ApCAh",
   "metadata": {
    "id": "wkh32O7ApCAh"
   },
   "outputs": [],
   "source": [
    "chat_words = {\n",
    "    \"$\" : \" dollar \",\n",
    "    \"€\" : \" euro \",\n",
    "    \"4ao\" : \"for adults only\",\n",
    "    \"a.m\" : \"before midday\",\n",
    "    \"a3\" : \"anytime anywhere anyplace\",\n",
    "    \"aamof\" : \"as a matter of fact\",\n",
    "    \"acct\" : \"account\",\n",
    "    \"adih\" : \"another day in hell\",\n",
    "    \"afaic\" : \"as far as i am concerned\",\n",
    "    \"afaict\" : \"as far as i can tell\",\n",
    "    \"afaik\" : \"as far as i know\",\n",
    "    \"afair\" : \"as far as i remember\",\n",
    "    \"afk\" : \"away from keyboard\",\n",
    "    \"app\" : \"application\",\n",
    "    \"approx\" : \"approximately\",\n",
    "    \"apps\" : \"applications\",\n",
    "    \"asap\" : \"as soon as possible\",\n",
    "    \"asl\" : \"age, sex, location\",\n",
    "    \"atk\" : \"at the keyboard\",\n",
    "    \"ave.\" : \"avenue\",\n",
    "    \"aymm\" : \"are you my mother\",\n",
    "    \"ayor\" : \"at your own risk\",\n",
    "    \"b&b\" : \"bed and breakfast\",\n",
    "    \"b+b\" : \"bed and breakfast\",\n",
    "    \"b.c\" : \"before christ\",\n",
    "    \"b2b\" : \"business to business\",\n",
    "    \"b2c\" : \"business to customer\",\n",
    "    \"b4\" : \"before\",\n",
    "    \"b4n\" : \"bye for now\",\n",
    "    \"b@u\" : \"back at you\",\n",
    "    \"bae\" : \"before anyone else\",\n",
    "    \"bak\" : \"back at keyboard\",\n",
    "    \"bbbg\" : \"bye bye be good\",\n",
    "    \"bbc\" : \"british broadcasting corporation\",\n",
    "    \"bbias\" : \"be back in a second\",\n",
    "    \"bbl\" : \"be back later\",\n",
    "    \"bbs\" : \"be back soon\",\n",
    "    \"be4\" : \"before\",\n",
    "    \"bfn\" : \"bye for now\",\n",
    "    \"blvd\" : \"boulevard\",\n",
    "    \"bout\" : \"about\",\n",
    "    \"brb\" : \"be right back\",\n",
    "    \"bros\" : \"brothers\",\n",
    "    \"brt\" : \"be right there\",\n",
    "    \"bsaaw\" : \"big smile and a wink\",\n",
    "    \"btw\" : \"by the way\",\n",
    "    \"bwl\" : \"bursting with laughter\",\n",
    "    \"c/o\" : \"care of\",\n",
    "    \"cet\" : \"central european time\",\n",
    "    \"cf\" : \"compare\",\n",
    "    \"cia\" : \"central intelligence agency\",\n",
    "    \"csl\" : \"can not stop laughing\",\n",
    "    \"cu\" : \"see you\",\n",
    "    \"cul8r\" : \"see you later\",\n",
    "    \"cv\" : \"curriculum vitae\",\n",
    "    \"cwot\" : \"complete waste of time\",\n",
    "    \"cya\" : \"see you\",\n",
    "    \"cyt\" : \"see you tomorrow\",\n",
    "    \"dae\" : \"does anyone else\",\n",
    "    \"dbmib\" : \"do not bother me i am busy\",\n",
    "    \"diy\" : \"do it yourself\",\n",
    "    \"dm\" : \"direct message\",\n",
    "    \"dwh\" : \"during work hours\",\n",
    "    \"e123\" : \"easy as one two three\",\n",
    "    \"eet\" : \"eastern european time\",\n",
    "    \"eg\" : \"example\",\n",
    "    \"embm\" : \"early morning business meeting\",\n",
    "    \"encl\" : \"enclosed\",\n",
    "    \"encl.\" : \"enclosed\",\n",
    "    \"etc\" : \"and so on\",\n",
    "    \"faq\" : \"frequently asked questions\",\n",
    "    \"fawc\" : \"for anyone who cares\",\n",
    "    \"fb\" : \"facebook\",\n",
    "    \"fc\" : \"fingers crossed\",\n",
    "    \"fig\" : \"figure\",\n",
    "    \"fimh\" : \"forever in my heart\",\n",
    "    \"ft.\" : \"feet\",\n",
    "    \"ft\" : \"featuring\",\n",
    "    \"ftl\" : \"for the loss\",\n",
    "    \"ftw\" : \"for the win\",\n",
    "    \"fwiw\" : \"for what it is worth\",\n",
    "    \"fyi\" : \"for your information\",\n",
    "    \"g9\" : \"genius\",\n",
    "    \"gahoy\" : \"get a hold of yourself\",\n",
    "    \"gal\" : \"get a life\",\n",
    "    \"gcse\" : \"general certificate of secondary education\",\n",
    "    \"gfn\" : \"gone for now\",\n",
    "    \"gg\" : \"good game\",\n",
    "    \"gl\" : \"good luck\",\n",
    "    \"glhf\" : \"good luck have fun\",\n",
    "    \"gmt\" : \"greenwich mean time\",\n",
    "    \"gmta\" : \"great minds think alike\",\n",
    "    \"gn\" : \"good night\",\n",
    "    \"g.o.a.t\" : \"greatest of all time\",\n",
    "    \"goat\" : \"greatest of all time\",\n",
    "    \"goi\" : \"get over it\",\n",
    "    \"gps\" : \"global positioning system\",\n",
    "    \"gr8\" : \"great\",\n",
    "    \"gratz\" : \"congratulations\",\n",
    "    \"gyal\" : \"girl\",\n",
    "    \"h&c\" : \"hot and cold\",\n",
    "    \"hp\" : \"horsepower\",\n",
    "    \"hr\" : \"hour\",\n",
    "    \"hrh\" : \"his royal highness\",\n",
    "    \"ht\" : \"height\",\n",
    "    \"ibrb\" : \"i will be right back\",\n",
    "    \"ic\" : \"i see\",\n",
    "    \"icq\" : \"i seek you\",\n",
    "    \"icymi\" : \"in case you missed it\",\n",
    "    \"idc\" : \"i do not care\",\n",
    "    \"idgadf\" : \"i do not give a damn fuck\",\n",
    "    \"idgaf\" : \"i do not give a fuck\",\n",
    "    \"idk\" : \"i do not know\",\n",
    "    \"ie\" : \"that is\",\n",
    "    \"i.e\" : \"that is\",\n",
    "    \"ifyp\" : \"i feel your pain\",\n",
    "    \"IG\" : \"instagram\",\n",
    "    \"iirc\" : \"if i remember correctly\",\n",
    "    \"ilu\" : \"i love you\",\n",
    "    \"ily\" : \"i love you\",\n",
    "    \"imho\" : \"in my humble opinion\",\n",
    "    \"imo\" : \"in my opinion\",\n",
    "    \"imu\" : \"i miss you\",\n",
    "    \"iow\" : \"in other words\",\n",
    "    \"irl\" : \"in real life\",\n",
    "    \"j4f\" : \"just for fun\",\n",
    "    \"jic\" : \"just in case\",\n",
    "    \"jk\" : \"just kidding\",\n",
    "    \"jsyk\" : \"just so you know\",\n",
    "    \"l8r\" : \"later\",\n",
    "    \"lb\" : \"pound\",\n",
    "    \"lbs\" : \"pounds\",\n",
    "    \"ldr\" : \"long distance relationship\",\n",
    "    \"lmao\" : \"laugh my ass off\",\n",
    "    \"lmfao\" : \"laugh my fucking ass off\",\n",
    "    \"lol\" : \"laughing out loud\",\n",
    "    \"ltd\" : \"limited\",\n",
    "    \"ltns\" : \"long time no see\",\n",
    "    \"m8\" : \"mate\",\n",
    "    \"mf\" : \"motherfucker\",\n",
    "    \"mfs\" : \"motherfuckers\",\n",
    "    \"mfw\" : \"my face when\",\n",
    "    \"mofo\" : \"motherfucker\",\n",
    "    \"mph\" : \"miles per hour\",\n",
    "    \"mr\" : \"mister\",\n",
    "    \"mrw\" : \"my reaction when\",\n",
    "    \"ms\" : \"miss\",\n",
    "    \"mte\" : \"my thoughts exactly\",\n",
    "    \"nagi\" : \"not a good idea\",\n",
    "    \"nbc\" : \"national broadcasting company\",\n",
    "    \"nbd\" : \"not big deal\",\n",
    "    \"nfs\" : \"not for sale\",\n",
    "    \"ngl\" : \"not going to lie\",\n",
    "    \"nhs\" : \"national health service\",\n",
    "    \"nrn\" : \"no reply necessary\",\n",
    "    \"nsfl\" : \"not safe for life\",\n",
    "    \"nsfw\" : \"not safe for work\",\n",
    "    \"nth\" : \"nice to have\",\n",
    "    \"nvr\" : \"never\",\n",
    "    \"nyc\" : \"new york city\",\n",
    "    \"oc\" : \"original content\",\n",
    "    \"og\" : \"original\",\n",
    "    \"ohp\" : \"overhead projector\",\n",
    "    \"oic\" : \"oh i see\",\n",
    "    \"omdb\" : \"over my dead body\",\n",
    "    \"omg\" : \"oh my god\",\n",
    "    \"omw\" : \"on my way\",\n",
    "    \"p.a\" : \"per annum\",\n",
    "    \"p.m\" : \"after midday\",\n",
    "    \"pm\" : \"prime minister\",\n",
    "    \"poc\" : \"people of color\",\n",
    "    \"pov\" : \"point of view\",\n",
    "    \"pp\" : \"pages\",\n",
    "    \"ppl\" : \"people\",\n",
    "    \"prw\" : \"parents are watching\",\n",
    "    \"ps\" : \"postscript\",\n",
    "    \"pt\" : \"point\",\n",
    "    \"ptb\" : \"please text back\",\n",
    "    \"pto\" : \"please turn over\",\n",
    "    \"qpsa\" : \"what happens\", #\"que pasa\",\n",
    "    \"ratchet\" : \"rude\",\n",
    "    \"rbtl\" : \"read between the lines\",\n",
    "    \"rlrt\" : \"real life retweet\",\n",
    "    \"rofl\" : \"rolling on the floor laughing\",\n",
    "    \"roflol\" : \"rolling on the floor laughing out loud\",\n",
    "    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
    "    \"rt\" : \"retweet\",\n",
    "    \"ruok\" : \"are you ok\",\n",
    "    \"sfw\" : \"safe for work\",\n",
    "    \"sk8\" : \"skate\",\n",
    "    \"smh\" : \"shake my head\",\n",
    "    \"sq\" : \"square\",\n",
    "    \"srsly\" : \"seriously\",\n",
    "    \"ssdd\" : \"same stuff different day\",\n",
    "    \"tbh\" : \"to be honest\",\n",
    "    \"tbs\" : \"tablespooful\",\n",
    "    \"tbsp\" : \"tablespooful\",\n",
    "    \"tfw\" : \"that feeling when\",\n",
    "    \"thks\" : \"thank you\",\n",
    "    \"tho\" : \"though\",\n",
    "    \"thx\" : \"thank you\",\n",
    "    \"tia\" : \"thanks in advance\",\n",
    "    \"til\" : \"today i learned\",\n",
    "    \"tl;dr\" : \"too long i did not read\",\n",
    "    \"tldr\" : \"too long i did not read\",\n",
    "    \"tmb\" : \"tweet me back\",\n",
    "    \"tntl\" : \"trying not to laugh\",\n",
    "    \"ttyl\" : \"talk to you later\",\n",
    "    \"u\" : \"you\",\n",
    "    \"u2\" : \"you too\",\n",
    "    \"u4e\" : \"yours for ever\",\n",
    "    \"utc\" : \"coordinated universal time\",\n",
    "    \"w/\" : \"with\",\n",
    "    \"w/o\" : \"without\",\n",
    "    \"w8\" : \"wait\",\n",
    "    \"wassup\" : \"what is up\",\n",
    "    \"wb\" : \"welcome back\",\n",
    "    \"wtf\" : \"what the fuck\",\n",
    "    \"wtg\" : \"way to go\",\n",
    "    \"wtpa\" : \"where the party at\",\n",
    "    \"wuf\" : \"where are you from\",\n",
    "    \"wuzup\" : \"what is up\",\n",
    "    \"wywh\" : \"wish you were here\",\n",
    "    \"yd\" : \"yard\",\n",
    "    \"ygtr\" : \"you got that right\",\n",
    "    \"ynk\" : \"you never know\",\n",
    "    \"zzz\" : \"sleeping bored and tired\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ioem3ojpXKj",
   "metadata": {
    "id": "4ioem3ojpXKj"
   },
   "outputs": [],
   "source": [
    "def chat_conversion(text):\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w in chat_words:\n",
    "            new_text.append(chat_words[w])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "hFrgo7ANpaxc",
   "metadata": {
    "id": "hFrgo7ANpaxc"
   },
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(chat_conversion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HU4j9dTzpkWb",
   "metadata": {
    "id": "HU4j9dTzpkWb"
   },
   "source": [
    "### Remove `EMOJI` if there is any emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "mh183reeplpo",
   "metadata": {
    "id": "mh183reeplpo"
   },
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8yH5qET2pnFo",
   "metadata": {
    "id": "8yH5qET2pnFo"
   },
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_emoji)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Qjz6lruuqMUM",
   "metadata": {
    "id": "Qjz6lruuqMUM"
   },
   "source": [
    "### Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6tCvinYGpm8n",
   "metadata": {
    "id": "6tCvinYGpm8n"
   },
   "outputs": [],
   "source": [
    "exclude = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "UVvvq_YZpm6D",
   "metadata": {
    "id": "UVvvq_YZpm6D"
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('','',exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcH6y4OvqD1e",
   "metadata": {
    "id": "dcH6y4OvqD1e"
   },
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Bz2wmE6EqR-S",
   "metadata": {
    "id": "Bz2wmE6EqR-S"
   },
   "source": [
    "### Remove Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bdc39311",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bdc39311",
    "outputId": "cc18c4a5-27d4-4efb-9c82-bb0bfb3d4614"
   },
   "outputs": [],
   "source": [
    "sw_list = stopwords.words('english')\n",
    "\n",
    "df['review'] = df['review'].apply(lambda x: [item for item in x.split() if item not in sw_list]).apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb3beebd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "eb3beebd",
    "outputId": "5637070c-3032-4ad7-b88d-5e4877e64357"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>thought movie right good job wasnt creative or...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>catholic taught parochial elementary schools n...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>im going disagree previous comment side maltin...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>one expects star trek movies high art fans exp...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49582 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one reviewers mentioned watching 1 oz episode ...  positive\n",
       "1      wonderful little production filming technique ...  positive\n",
       "2      thought wonderful way spend time hot summer we...  positive\n",
       "3      basically theres family little boy jake thinks...  negative\n",
       "4      petter matteis love time money visually stunni...  positive\n",
       "...                                                  ...       ...\n",
       "49995  thought movie right good job wasnt creative or...  positive\n",
       "49996  bad plot bad dialogue bad acting idiotic direc...  negative\n",
       "49997  catholic taught parochial elementary schools n...  negative\n",
       "49998  im going disagree previous comment side maltin...  negative\n",
       "49999  one expects star trek movies high art fans exp...  negative\n",
       "\n",
       "[49582 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7C9VJNO9qWYT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "7C9VJNO9qWYT",
    "outputId": "40960d17-9c20-4618-b1a3-300b2226417a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'im big fan bolls work many enjoyed movie postal maybe im one boll apparently bought rights use far cry long ago even game even finsished people enjoyed killing mercs infiltrating secret research labs located tropical island warned far cry something mister boll schemed together along legion schmucks feeling loneley set mister boll invites three countrymen play players go names today learned schweiger udo kier ralf moellerthree names actually made selfs pretty big movie biz tale goes like jack carver played today learned schweiger yes carver german hail bratwurst eating dudes however find tils acting movie pretty badass people complained hes really staying true whole carver agenda saw carver first person perspective dont really know looked like kicking however storyline film beyond demented see evil mad scientist dr krieger played udo kier making geneticallymutatedsoldiers gms called performing topsecret research island reminds spoiler vancouver reason thats right palm trees instead got nice rich lumberjackwoods havent even gone far started cry mehehe cannot go wanna stay true bolls shenanigans go see movie disappointed delivers true boll experience meaning suckthere things worth mentioning would imply boll good work areas film nice boat fighting scenes whole cromedalbino gms squad enters scene everything makes laugh movie far cry reeks scheisse thats poop simpletons far wanna take wiff go ahead way carver gets annoying sidekick makes wanna shoot first three minutes hes screen'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"review\"][12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZXNldCOcqW_6",
   "metadata": {
    "id": "ZXNldCOcqW_6"
   },
   "source": [
    "### Now Tokenize the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aisw6wFHqWVy",
   "metadata": {
    "id": "aisw6wFHqWVy"
   },
   "outputs": [],
   "source": [
    "def tokenize_with_nltk(text):\n",
    "    return nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "FAvesQONqWME",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FAvesQONqWME",
    "outputId": "1834a599-2f4d-448c-cee7-92845d44f7f2"
   },
   "outputs": [],
   "source": [
    "tokens = df['review'].apply(tokenize_with_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "EiY09eVuqWI-",
   "metadata": {
    "id": "EiY09eVuqWI-"
   },
   "outputs": [],
   "source": [
    "df['tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "kDXpGc87tK3q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "kDXpGc87tK3q",
    "outputId": "a0380855-4c98-435f-cce4-2313222506b9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[one, reviewers, mentioned, watching, 1, oz, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[wonderful, little, production, filming, techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[basically, theres, family, little, boy, jake,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[petter, matteis, love, time, money, visually,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>thought movie right good job wasnt creative or...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, movie, right, good, job, wasnt, crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[bad, plot, bad, dialogue, bad, acting, idioti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>catholic taught parochial elementary schools n...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[catholic, taught, parochial, elementary, scho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>im going disagree previous comment side maltin...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[im, going, disagree, previous, comment, side,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>one expects star trek movies high art fans exp...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[one, expects, star, trek, movies, high, art, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49582 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "0      one reviewers mentioned watching 1 oz episode ...  positive   \n",
       "1      wonderful little production filming technique ...  positive   \n",
       "2      thought wonderful way spend time hot summer we...  positive   \n",
       "3      basically theres family little boy jake thinks...  negative   \n",
       "4      petter matteis love time money visually stunni...  positive   \n",
       "...                                                  ...       ...   \n",
       "49995  thought movie right good job wasnt creative or...  positive   \n",
       "49996  bad plot bad dialogue bad acting idiotic direc...  negative   \n",
       "49997  catholic taught parochial elementary schools n...  negative   \n",
       "49998  im going disagree previous comment side maltin...  negative   \n",
       "49999  one expects star trek movies high art fans exp...  negative   \n",
       "\n",
       "                                                  tokens  \n",
       "0      [one, reviewers, mentioned, watching, 1, oz, e...  \n",
       "1      [wonderful, little, production, filming, techn...  \n",
       "2      [thought, wonderful, way, spend, time, hot, su...  \n",
       "3      [basically, theres, family, little, boy, jake,...  \n",
       "4      [petter, matteis, love, time, money, visually,...  \n",
       "...                                                  ...  \n",
       "49995  [thought, movie, right, good, job, wasnt, crea...  \n",
       "49996  [bad, plot, bad, dialogue, bad, acting, idioti...  \n",
       "49997  [catholic, taught, parochial, elementary, scho...  \n",
       "49998  [im, going, disagree, previous, comment, side,...  \n",
       "49999  [one, expects, star, trek, movies, high, art, ...  \n",
       "\n",
       "[49582 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "hCjhsmEGtK0S",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hCjhsmEGtK0S",
    "outputId": "f76837a4-8b86-442f-b321-3c9bc7151f95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['phil',\n",
       " 'alien',\n",
       " 'one',\n",
       " 'quirky',\n",
       " 'films',\n",
       " 'humour',\n",
       " 'based',\n",
       " 'around',\n",
       " 'oddness',\n",
       " 'everything',\n",
       " 'rather',\n",
       " 'actual',\n",
       " 'punchlinesat',\n",
       " 'first',\n",
       " 'odd',\n",
       " 'pretty',\n",
       " 'funny',\n",
       " 'movie',\n",
       " 'progressed',\n",
       " 'didnt',\n",
       " 'find',\n",
       " 'jokes',\n",
       " 'oddness',\n",
       " 'funny',\n",
       " 'anymoreits',\n",
       " 'low',\n",
       " 'budget',\n",
       " 'film',\n",
       " 'thats',\n",
       " 'never',\n",
       " 'problem',\n",
       " 'pretty',\n",
       " 'interesting',\n",
       " 'characters',\n",
       " 'eventually',\n",
       " 'lost',\n",
       " 'interesti',\n",
       " 'imagine',\n",
       " 'film',\n",
       " 'would',\n",
       " 'appeal',\n",
       " 'stoner',\n",
       " 'currently',\n",
       " 'partakingfor',\n",
       " 'something',\n",
       " 'similar',\n",
       " 'better',\n",
       " 'try',\n",
       " 'brother',\n",
       " 'another',\n",
       " 'planet']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h4m2pwost42Y",
   "metadata": {
    "id": "h4m2pwost42Y"
   },
   "source": [
    "### Lemmatization for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "wdb2682wtKyP",
   "metadata": {
    "id": "wdb2682wtKyP"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_tokens(tokens):\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "mMkVV1UltKv2",
   "metadata": {
    "id": "mMkVV1UltKv2"
   },
   "outputs": [],
   "source": [
    "df['lemmatize_tokens'] = tokens.apply(lemmatize_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ONNtp8ImuH2z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "id": "ONNtp8ImuH2z",
    "outputId": "7f6d012e-056b-4b1d-ffa4-c1b5fc99ff04"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmatize_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[one, reviewers, mentioned, watching, 1, oz, e...</td>\n",
       "      <td>[one, reviewer, mentioned, watching, 1, oz, ep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[wonderful, little, production, filming, techn...</td>\n",
       "      <td>[wonderful, little, production, filming, techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[basically, theres, family, little, boy, jake,...</td>\n",
       "      <td>[basically, there, family, little, boy, jake, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[petter, matteis, love, time, money, visually,...</td>\n",
       "      <td>[petter, matteis, love, time, money, visually,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>thought movie right good job wasnt creative or...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, movie, right, good, job, wasnt, crea...</td>\n",
       "      <td>[thought, movie, right, good, job, wasnt, crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[bad, plot, bad, dialogue, bad, acting, idioti...</td>\n",
       "      <td>[bad, plot, bad, dialogue, bad, acting, idioti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>catholic taught parochial elementary schools n...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[catholic, taught, parochial, elementary, scho...</td>\n",
       "      <td>[catholic, taught, parochial, elementary, scho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>im going disagree previous comment side maltin...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[im, going, disagree, previous, comment, side,...</td>\n",
       "      <td>[im, going, disagree, previous, comment, side,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>one expects star trek movies high art fans exp...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[one, expects, star, trek, movies, high, art, ...</td>\n",
       "      <td>[one, expects, star, trek, movie, high, art, f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49582 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "0      one reviewers mentioned watching 1 oz episode ...  positive   \n",
       "1      wonderful little production filming technique ...  positive   \n",
       "2      thought wonderful way spend time hot summer we...  positive   \n",
       "3      basically theres family little boy jake thinks...  negative   \n",
       "4      petter matteis love time money visually stunni...  positive   \n",
       "...                                                  ...       ...   \n",
       "49995  thought movie right good job wasnt creative or...  positive   \n",
       "49996  bad plot bad dialogue bad acting idiotic direc...  negative   \n",
       "49997  catholic taught parochial elementary schools n...  negative   \n",
       "49998  im going disagree previous comment side maltin...  negative   \n",
       "49999  one expects star trek movies high art fans exp...  negative   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      [one, reviewers, mentioned, watching, 1, oz, e...   \n",
       "1      [wonderful, little, production, filming, techn...   \n",
       "2      [thought, wonderful, way, spend, time, hot, su...   \n",
       "3      [basically, theres, family, little, boy, jake,...   \n",
       "4      [petter, matteis, love, time, money, visually,...   \n",
       "...                                                  ...   \n",
       "49995  [thought, movie, right, good, job, wasnt, crea...   \n",
       "49996  [bad, plot, bad, dialogue, bad, acting, idioti...   \n",
       "49997  [catholic, taught, parochial, elementary, scho...   \n",
       "49998  [im, going, disagree, previous, comment, side,...   \n",
       "49999  [one, expects, star, trek, movies, high, art, ...   \n",
       "\n",
       "                                        lemmatize_tokens  \n",
       "0      [one, reviewer, mentioned, watching, 1, oz, ep...  \n",
       "1      [wonderful, little, production, filming, techn...  \n",
       "2      [thought, wonderful, way, spend, time, hot, su...  \n",
       "3      [basically, there, family, little, boy, jake, ...  \n",
       "4      [petter, matteis, love, time, money, visually,...  \n",
       "...                                                  ...  \n",
       "49995  [thought, movie, right, good, job, wasnt, crea...  \n",
       "49996  [bad, plot, bad, dialogue, bad, acting, idioti...  \n",
       "49997  [catholic, taught, parochial, elementary, scho...  \n",
       "49998  [im, going, disagree, previous, comment, side,...  \n",
       "49999  [one, expects, star, trek, movie, high, art, f...  \n",
       "\n",
       "[49582 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afXjTv3IuRaP",
   "metadata": {
    "id": "afXjTv3IuRaP"
   },
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aJvk_zIiuTPr",
   "metadata": {
    "id": "aJvk_zIiuTPr"
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "IoFSVjInuTNq",
   "metadata": {
    "id": "IoFSVjInuTNq"
   },
   "outputs": [],
   "source": [
    "df['Stemming'] = df['tokens'].apply(stem_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14c9589e-26bb-44bc-a46a-4c2ff3c502bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will get a list of stemming words for each sentence so convert it into string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ao5_KpPU0umg",
   "metadata": {
    "id": "ao5_KpPU0umg"
   },
   "outputs": [],
   "source": [
    "df['Stemming'] = df['Stemming'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "HylF3C8i02Pf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 770
    },
    "id": "HylF3C8i02Pf",
    "outputId": "bef19fc9-416f-464a-80cb-46003d49b9e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmatize_tokens</th>\n",
       "      <th>Stemming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[one, reviewers, mentioned, watching, 1, oz, e...</td>\n",
       "      <td>[one, reviewer, mentioned, watching, 1, oz, ep...</td>\n",
       "      <td>one review mention watch 1 oz episod youll hoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[wonderful, little, production, filming, techn...</td>\n",
       "      <td>[wonderful, little, production, filming, techn...</td>\n",
       "      <td>wonder littl product film techniqu unassum old...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "      <td>thought wonder way spend time hot summer weeke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[basically, theres, family, little, boy, jake,...</td>\n",
       "      <td>[basically, there, family, little, boy, jake, ...</td>\n",
       "      <td>basic there famili littl boy jake think there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[petter, matteis, love, time, money, visually,...</td>\n",
       "      <td>[petter, matteis, love, time, money, visually,...</td>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>thought movie right good job wasnt creative or...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, movie, right, good, job, wasnt, crea...</td>\n",
       "      <td>[thought, movie, right, good, job, wasnt, crea...</td>\n",
       "      <td>thought movi right good job wasnt creativ orig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[bad, plot, bad, dialogue, bad, acting, idioti...</td>\n",
       "      <td>[bad, plot, bad, dialogue, bad, acting, idioti...</td>\n",
       "      <td>bad plot bad dialogu bad act idiot direct anno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>catholic taught parochial elementary schools n...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[catholic, taught, parochial, elementary, scho...</td>\n",
       "      <td>[catholic, taught, parochial, elementary, scho...</td>\n",
       "      <td>cathol taught parochi elementari school nun ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>im going disagree previous comment side maltin...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[im, going, disagree, previous, comment, side,...</td>\n",
       "      <td>[im, going, disagree, previous, comment, side,...</td>\n",
       "      <td>im go disagre previou comment side maltin one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>one expects star trek movies high art fans exp...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[one, expects, star, trek, movies, high, art, ...</td>\n",
       "      <td>[one, expects, star, trek, movie, high, art, f...</td>\n",
       "      <td>one expect star trek movi high art fan expect ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49582 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "0      one reviewers mentioned watching 1 oz episode ...  positive   \n",
       "1      wonderful little production filming technique ...  positive   \n",
       "2      thought wonderful way spend time hot summer we...  positive   \n",
       "3      basically theres family little boy jake thinks...  negative   \n",
       "4      petter matteis love time money visually stunni...  positive   \n",
       "...                                                  ...       ...   \n",
       "49995  thought movie right good job wasnt creative or...  positive   \n",
       "49996  bad plot bad dialogue bad acting idiotic direc...  negative   \n",
       "49997  catholic taught parochial elementary schools n...  negative   \n",
       "49998  im going disagree previous comment side maltin...  negative   \n",
       "49999  one expects star trek movies high art fans exp...  negative   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      [one, reviewers, mentioned, watching, 1, oz, e...   \n",
       "1      [wonderful, little, production, filming, techn...   \n",
       "2      [thought, wonderful, way, spend, time, hot, su...   \n",
       "3      [basically, theres, family, little, boy, jake,...   \n",
       "4      [petter, matteis, love, time, money, visually,...   \n",
       "...                                                  ...   \n",
       "49995  [thought, movie, right, good, job, wasnt, crea...   \n",
       "49996  [bad, plot, bad, dialogue, bad, acting, idioti...   \n",
       "49997  [catholic, taught, parochial, elementary, scho...   \n",
       "49998  [im, going, disagree, previous, comment, side,...   \n",
       "49999  [one, expects, star, trek, movies, high, art, ...   \n",
       "\n",
       "                                        lemmatize_tokens  \\\n",
       "0      [one, reviewer, mentioned, watching, 1, oz, ep...   \n",
       "1      [wonderful, little, production, filming, techn...   \n",
       "2      [thought, wonderful, way, spend, time, hot, su...   \n",
       "3      [basically, there, family, little, boy, jake, ...   \n",
       "4      [petter, matteis, love, time, money, visually,...   \n",
       "...                                                  ...   \n",
       "49995  [thought, movie, right, good, job, wasnt, crea...   \n",
       "49996  [bad, plot, bad, dialogue, bad, acting, idioti...   \n",
       "49997  [catholic, taught, parochial, elementary, scho...   \n",
       "49998  [im, going, disagree, previous, comment, side,...   \n",
       "49999  [one, expects, star, trek, movie, high, art, f...   \n",
       "\n",
       "                                                Stemming  \n",
       "0      one review mention watch 1 oz episod youll hoo...  \n",
       "1      wonder littl product film techniqu unassum old...  \n",
       "2      thought wonder way spend time hot summer weeke...  \n",
       "3      basic there famili littl boy jake think there ...  \n",
       "4      petter mattei love time money visual stun film...  \n",
       "...                                                  ...  \n",
       "49995  thought movi right good job wasnt creativ orig...  \n",
       "49996  bad plot bad dialogu bad act idiot direct anno...  \n",
       "49997  cathol taught parochi elementari school nun ta...  \n",
       "49998  im go disagre previou comment side maltin one ...  \n",
       "49999  one expect star trek movi high art fan expect ...  \n",
       "\n",
       "[49582 rows x 5 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683982a5",
   "metadata": {},
   "source": [
    "# Prepare Input and Output For Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "044b8b36",
   "metadata": {
    "id": "044b8b36"
   },
   "outputs": [],
   "source": [
    "X = df['Stemming']\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2f50b0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2f50b0d",
    "outputId": "81a7dbbc-fbb4-4ddf-ce1d-c3624b46e507"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one review mention watch 1 oz episod youll hoo...\n",
       "1        wonder littl product film techniqu unassum old...\n",
       "2        thought wonder way spend time hot summer weeke...\n",
       "3        basic there famili littl boy jake think there ...\n",
       "4        petter mattei love time money visual stun film...\n",
       "                               ...                        \n",
       "49995    thought movi right good job wasnt creativ orig...\n",
       "49996    bad plot bad dialogu bad act idiot direct anno...\n",
       "49997    cathol taught parochi elementari school nun ta...\n",
       "49998    im go disagre previou comment side maltin one ...\n",
       "49999    one expect star trek movi high art fan expect ...\n",
       "Name: Stemming, Length: 49582, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6014ee0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c6014ee0",
    "outputId": "4087ef61-f3b0-4ff8-ad61-b18bee157471"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        positive\n",
       "1        positive\n",
       "2        positive\n",
       "3        negative\n",
       "4        positive\n",
       "           ...   \n",
       "49995    positive\n",
       "49996    negative\n",
       "49997    negative\n",
       "49998    negative\n",
       "49999    negative\n",
       "Name: sentiment, Length: 49582, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4309c7",
   "metadata": {},
   "source": [
    "### Convert the values of Y column or output column in 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fb01ea97",
   "metadata": {
    "id": "fb01ea97"
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e49f7132",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e49f7132",
    "outputId": "cf5452a0-fb8b-4f17-ea94-c0d0c8ef5117"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250e0676",
   "metadata": {},
   "source": [
    "### Split your data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a47c8cf",
   "metadata": {
    "id": "4a47c8cf"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "59d30e1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59d30e1a",
    "outputId": "46417644-1966-43a8-bbd0-672354cf4337"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39665,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425a758f",
   "metadata": {},
   "source": [
    "# Apply Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd7fa4",
   "metadata": {},
   "source": [
    "### 1. Apply `BOW` to convert a text into `Vector` for our Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d038ae3a",
   "metadata": {
    "id": "d038ae3a"
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ozZlYYHYzXxf",
   "metadata": {
    "id": "ozZlYYHYzXxf"
   },
   "outputs": [],
   "source": [
    "# Now apply CountVectorizer\n",
    "X_train_bow = cv.fit_transform(X_train).toarray()\n",
    "X_test_bow = cv.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "98e12175",
   "metadata": {
    "id": "98e12175",
    "outputId": "db7af72f-3d46-4488-ff11-d6e3d624135c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39665, 5000)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc53e60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import loguniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8472ff3d",
   "metadata": {},
   "source": [
    "#### 1. Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "381cb957-60dd-4f28-b080-b2b4294ebc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.73238371 0.7309971  0.72898021 0.72355981 0.71889575]\n",
      "Mean accuracy of model: 0.7269633177864616\n"
     ]
    }
   ],
   "source": [
    "gnb_bow = GaussianNB()\n",
    "\n",
    "cv_scores = cross_val_score(gnb_bow, X_train_bow, y_train, cv=5, n_jobs = 6)\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "\n",
    "gnb_bow_accuracy = np.mean(cv_scores)\n",
    "print(\"Mean accuracy of model:\", gnb_bow_accuracy)\n",
    "\n",
    "gnb_bow.fit(X_train_bow, y_train) \n",
    "\n",
    "y_pred_gnb_bow = gnb_bow.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8846a6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.74353394874409\n",
      "Recall: 0.729353635171927\n",
      "F1 Score: 0.7245639335885092\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision, recall, and F1 score\n",
    "precision_gnb_bow = precision_score(y_test, y_pred_gnb_bow, average='weighted')  # or 'macro', 'micro', etc.\n",
    "recall_gnb_bow = recall_score(y_test, y_pred_gnb_bow, average='weighted')\n",
    "f1_score_gnb_bow = f1_score(y_test, y_pred_gnb_bow, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print(\"Precision:\", precision_gnb_bow)\n",
    "print(\"Recall:\", recall_gnb_bow)\n",
    "print(\"F1 Score:\", f1_score_gnb_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a296edfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[4308  725]\n",
      " [1959 2925]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_gnb_bow = confusion_matrix(y_test, y_pred_gnb_bow)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix_gnb_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1f1e0b",
   "metadata": {},
   "source": [
    "#### 2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0aa37196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 12}\n"
     ]
    }
   ],
   "source": [
    "rf_bow = RandomForestClassifier()\n",
    "param_distributions = {\n",
    "    'n_estimators': [100, 200, 300], \n",
    "    'max_depth': [4, 8, 12],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "grid_search = RandomizedSearchCV(estimator=rf_bow, param_distributions=param_distributions , n_jobs=6)\n",
    "grid_search.fit(X_train_bow, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6676b0e0",
   "metadata": {
    "id": "6676b0e0",
    "outputId": "6502e4c6-f5f8-491e-931b-79ddc77eee93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.83839657 0.8346149  0.83373251 0.83524518 0.84772469]\n",
      "Mean accuracy of model: 0.8379427707046514\n"
     ]
    }
   ],
   "source": [
    "rf_bow = RandomForestClassifier(n_estimators=300, min_samples_split = 5,\n",
    "                           min_samples_leaf = 2, max_features = 'log2',\n",
    "                           max_depth = 12, n_jobs = 6)\n",
    "\n",
    "cv_scores = cross_val_score(rf_bow, X_train_bow, y_train, cv=5)\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "\n",
    "rf_bow_accuracy = np.mean(cv_scores)\n",
    "print(\"Mean accuracy of model:\", rf_bow_accuracy)\n",
    "\n",
    "rf_bow.fit(X_train_bow, y_train) \n",
    "\n",
    "y_pred_rf_bow = rf_bow.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2e965c22-8c30-4829-970a-fa4b6ffcc0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8400600392915734\n",
      "Recall: 0.8307956035091257\n",
      "F1 Score: 0.8298906512696285\n"
     ]
    }
   ],
   "source": [
    "precision_rf_bow = precision_score(y_test, y_pred_rf_bow, average='weighted')  # or 'macro', 'micro', etc.\n",
    "recall_rf_bow = recall_score(y_test, y_pred_rf_bow, average='weighted')\n",
    "f1_score_rf_bow = f1_score(y_test, y_pred_rf_bow, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Precision:\", precision_rf_bow)\n",
    "print(\"Recall:\", recall_rf_bow)\n",
    "print(\"F1 Score:\", f1_score_rf_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "79c81100-3b3b-48b8-9628-823359f11e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3793 1240]\n",
      " [ 438 4446]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_rf_bow = confusion_matrix(y_test, y_pred_rf_bow)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix_rf_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae08e2a",
   "metadata": {},
   "source": [
    "#### 3. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2b224adf-fafa-46c9-9ddb-c9a185a018f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'min_samples_split': 20, 'min_samples_leaf': 10, 'max_features': None, 'max_depth': 50, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 10],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "grid_search = RandomizedSearchCV(estimator=dt, param_distributions=param_grid, scoring='accuracy', n_jobs=8)\n",
    "\n",
    "grid_search.fit(X_train_bow, y_train)\n",
    "\n",
    "best_dt = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1b650e45-0fe6-473d-92ae-e087a87d4b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.74070339 0.74158578 0.7321316  0.73276188 0.73843439]\n",
      "Mean accuracy of model: 0.7371234085465777\n"
     ]
    }
   ],
   "source": [
    "dt_bow = DecisionTreeClassifier(min_samples_split=20, min_samples_leaf=10, max_depth=50,criterion='gini')\n",
    "\n",
    "cv_scores = cross_val_score(dt_bow, X_train_bow, y_train, cv=5, n_jobs=8)\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "\n",
    "dt_bow_accuracy = np.mean(cv_scores)\n",
    "print(\"Mean accuracy of model:\", dt_bow_accuracy)\n",
    "\n",
    "dt_bow.fit(X_train_bow, y_train) \n",
    "\n",
    "y_pred_dt_bow = dt_bow.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bee335a4-630e-46bf-b48d-c0850e6f1f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7335908463126383\n",
      "Recall: 0.7333871130382172\n",
      "F1 Score: 0.7333987431668987\n"
     ]
    }
   ],
   "source": [
    "precision_dt_bow = precision_score(y_test, y_pred_dt_bow, average='weighted')  # or 'macro', 'micro', etc.\n",
    "recall_dt_bow = recall_score(y_test, y_pred_dt_bow, average='weighted')\n",
    "f1_score_dt_bow = f1_score(y_test, y_pred_dt_bow, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Precision:\", precision_dt_bow)\n",
    "print(\"Recall:\", recall_dt_bow)\n",
    "print(\"F1 Score:\", f1_score_dt_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c5fa7941-8283-4f72-85dc-49d8dd5fff3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3656 1377]\n",
      " [1267 3617]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_dt_bow = confusion_matrix(y_test, y_pred_dt_bow)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix_dt_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d39e87",
   "metadata": {},
   "source": [
    "#### 4. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cf71dba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 0.1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'sag', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'solver': ['lbfgs', 'sag', 'liblinear']}\n",
    "\n",
    "grid_search = RandomizedSearchCV(lr, param_grid, scoring='accuracy', n_jobs = 8)\n",
    "grid_search.fit(X_train_bow, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best hyperparameters:\", best_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "47dea9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.88251607 0.88226396 0.87911257 0.87520484 0.88289424]\n",
      "Mean accuracy of model: 0.8803983360645405\n"
     ]
    }
   ],
   "source": [
    "lr_bow = LogisticRegression(C=0.1,max_iter=100,\n",
    "                        n_jobs=12,penalty=\"l2\",\n",
    "                        solver='sag')\n",
    "\n",
    "cv_scores = cross_val_score(lr_bow, X_train_bow, y_train, cv=5)\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "\n",
    "lr_bow_accuracy = np.mean(cv_scores)\n",
    "print(\"Mean accuracy of model:\", lr_bow_accuracy)\n",
    "\n",
    "lr_bow.fit(X_train_bow, y_train) \n",
    "y_pred_lr_bow = lr_bow.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "40811a40-87b8-42a3-96d7-e3fae9f0b72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8830296552403704\n",
      "Recall: 0.8825249571442977\n",
      "F1 Score: 0.8825209197287387\n"
     ]
    }
   ],
   "source": [
    "precision_lr_bow = precision_score(y_test, y_pred_lr_bow, average='weighted')  # or 'macro', 'micro', etc.\n",
    "recall_lr_bow = recall_score(y_test, y_pred_lr_bow, average='weighted')\n",
    "f1_score_lr_bow = f1_score(y_test, y_pred_lr_bow, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Precision:\", precision_lr_bow)\n",
    "print(\"Recall:\", recall_lr_bow)\n",
    "print(\"F1 Score:\", f1_score_lr_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9d2a155e-5f6f-4c4c-9bf7-cada4110d3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[4366  667]\n",
      " [ 498 4386]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_lr_bow = confusion_matrix(y_test, y_pred_lr_bow)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix_lr_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852225ad",
   "metadata": {},
   "source": [
    "#### 5. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1ec3fe5b-a680-4077-adc2-513e63d08196",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "84b76e36-5b84-4606-af2e-4caf9cce0456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply CountVectorizer\n",
    "X_train_bow = cv.fit_transform(X_train).toarray()\n",
    "X_test_bow = cv.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5c05b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_bow = SVC(C=1, kernel=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "94e9a5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.86285138 0.86020421 0.85717887 0.85125425 0.86234716]\n",
      "Mean accuracy of model: 0.8587671750913903\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(svm_bow, X_train_bow, y_train, cv=5)\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "\n",
    "svm_bow_accuracy = np.mean(cv_scores)\n",
    "print(\"Mean accuracy of model:\", svm_bow_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ef1f51d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_bow.fit(X_train_bow, y_train)\n",
    "y_pred_svm_bow = svm_bow.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8493c9de-a7c8-467f-adaa-001a69bb1fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8617640845659432\n",
      "Recall: 0.8611475244529596\n",
      "F1 Score: 0.8611361982732547\n"
     ]
    }
   ],
   "source": [
    "precision_svm_bow = precision_score(y_test, y_pred_svm_bow, average='weighted')  # or 'macro', 'micro', etc.\n",
    "recall_svm_bow = recall_score(y_test, y_pred_svm_bow, average='weighted')\n",
    "f1_score_svm_bow = f1_score(y_test, y_pred_svm_bow, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Precision:\", precision_svm_bow)\n",
    "print(\"Recall:\", recall_svm_bow)\n",
    "print(\"F1 Score:\", f1_score_svm_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bc86f01e-1334-48b8-9fdd-8ef282a82d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[4249  784]\n",
      " [ 593 4291]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_svm_bow = confusion_matrix(y_test, y_pred_svm_bow)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix_svm_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108061b1-23bc-4941-95c7-115691e1aa6e",
   "metadata": {},
   "source": [
    "### `B` Now try with n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "14f397da-5352-4f22-9a10-9b6406a9d6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,5),max_features=5000)\n",
    "\n",
    "X_train_bow_ng = cv.fit_transform(X_train).toarray()\n",
    "X_test_bow_ng = cv.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9921cbe-e2be-437e-bf9a-3a58d638740a",
   "metadata": {},
   "source": [
    "#### 1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1da4c2f6-10f6-4dae-adea-53613100cc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.8400353  0.83032901 0.82768184 0.83184167 0.84268247]\n",
      "Mean accuracy of model: 0.834514055212404\n"
     ]
    }
   ],
   "source": [
    "rf_ngrams = RandomForestClassifier(n_estimators=300, min_samples_split = 5,\n",
    "                           min_samples_leaf = 2, max_features = 'log2',\n",
    "                           max_depth = 12, n_jobs = 6)\n",
    "\n",
    "cv_scores = cross_val_score(rf_ngrams, X_train_bow_ng, y_train, cv=5)\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "\n",
    "rf_ngrams_accuracy = np.mean(cv_scores)\n",
    "print(\"Mean accuracy of model:\", rf_ngrams_accuracy)\n",
    "\n",
    "rf_ngrams.fit(X_train_bow_ng, y_train) \n",
    "y_pred_rf_ngrams = rf_ngrams.predict(X_test_bow_ng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6909c44b-42b8-4bdd-b5a1-d1bb195fa5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8416226854466442\n",
      "Recall: 0.8289805384692952\n",
      "F1 Score: 0.8276853812048496\n"
     ]
    }
   ],
   "source": [
    "precision_rf_ngrams = precision_score(y_test, y_pred_rf_ngrams, average='weighted')  # or 'macro', 'micro', etc.\n",
    "recall_rf_ngrams = recall_score(y_test, y_pred_rf_ngrams, average='weighted')\n",
    "f1_score_rf_ngrams = f1_score(y_test, y_pred_rf_ngrams, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Precision:\", precision_rf_ngrams)\n",
    "print(\"Recall:\", recall_rf_ngrams)\n",
    "print(\"F1 Score:\", f1_score_rf_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed62b136-bdd3-4a84-8f20-8520217b2371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3716 1317]\n",
      " [ 379 4505]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_rf_ngrams = confusion_matrix(y_test, y_pred_rf_ngrams)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix_rf_ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872414cf-bc3e-473a-9c70-327d09a6d4ba",
   "metadata": {},
   "source": [
    "#### 2. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "30014382-e552-42c3-910d-331f137856ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.74284634 0.74259423 0.73477877 0.73250977 0.73629144]\n",
      "Mean accuracy of model: 0.7378041094163621\n"
     ]
    }
   ],
   "source": [
    "dt_ngrams = DecisionTreeClassifier(min_samples_split=20, min_samples_leaf=10, max_depth=50,criterion='gini')\n",
    "\n",
    "cv_scores = cross_val_score(dt_ngrams, X_train_bow_ng, y_train, cv=5)\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "\n",
    "dt_ngrams_accuracy = np.mean(cv_scores)\n",
    "print(\"Mean accuracy of model:\", dt_ngrams_accuracy)\n",
    "\n",
    "dt_ngrams.fit(X_train_bow_ng, y_train) \n",
    "y_pred_dt_ngrams = dt_ngrams.predict(X_test_bow_ng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fd684b7d-cb87-4e6b-84a0-6be7ecb3b5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.740509473250289\n",
      "Recall: 0.7404456993042251\n",
      "F1 Score: 0.7404587645048992\n"
     ]
    }
   ],
   "source": [
    "precision_dt_ngrams = precision_score(y_test, y_pred_dt_ngrams, average='weighted')  # or 'macro', 'micro', etc.\n",
    "recall_dt_ngrams = recall_score(y_test, y_pred_dt_ngrams, average='weighted')\n",
    "f1_score_dt_ngrams = f1_score(y_test, y_pred_dt_ngrams, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Precision:\", precision_dt_ngrams)\n",
    "print(\"Recall:\", recall_dt_ngrams)\n",
    "print(\"F1 Score:\", f1_score_dt_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "469a0b37-d272-4727-af7f-034ca8d3910c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3721 1312]\n",
      " [1262 3622]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_dt_ngrams = confusion_matrix(y_test, y_pred_dt_ngrams)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix_dt_ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa921083-3bfc-4c88-927c-eafcec08cbe5",
   "metadata": {},
   "source": [
    "#### 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1076222f-3e04-48a5-a565-c722c92d3f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.88327241 0.88201185 0.87961679 0.87860834 0.88604563]\n",
      "Mean accuracy of model: 0.8819110046640615\n"
     ]
    }
   ],
   "source": [
    "lr_ngrams = LogisticRegression(C=0.1,max_iter=100,\n",
    "                        n_jobs=12,penalty=\"l2\",\n",
    "                        solver='sag')\n",
    "\n",
    "cv_scores = cross_val_score(lr_ngrams, X_train_bow_ng, y_train, cv=5)\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "\n",
    "lr_ngrams_accuracy = np.mean(cv_scores)\n",
    "print(\"Mean accuracy of model:\", lr_ngrams_accuracy)\n",
    "\n",
    "lr_ngrams.fit(X_train_bow_ng, y_train) \n",
    "y_pred_lr_ngrams = lr_ngrams.predict(X_test_bow_ng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5db505f9-39ff-4655-94fb-f8d25527a21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8852382837575559\n",
      "Recall: 0.8847433699707573\n",
      "F1 Score: 0.8847398471082164\n"
     ]
    }
   ],
   "source": [
    "precision_lr_ngrams = precision_score(y_test, y_pred_lr_ngrams, average='weighted')  # or 'macro', 'micro', etc.\n",
    "recall_lr_ngrams = recall_score(y_test, y_pred_lr_ngrams, average='weighted')\n",
    "f1_score_lr_ngrams = f1_score(y_test, y_pred_lr_ngrams, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Precision:\", precision_lr_ngrams)\n",
    "print(\"Recall:\", recall_lr_ngrams)\n",
    "print(\"F1 Score:\", f1_score_lr_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b216bc6d-46c7-4dec-bc43-cfb71494fea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[4378  655]\n",
      " [ 488 4396]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_lr_ngrams = confusion_matrix(y_test, y_pred_lr_ngrams)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix_lr_ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802297c1-41ca-4a80-a8b4-9ee7f85257ea",
   "metadata": {},
   "source": [
    "#### 4. Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6af2aca8-ae63-47f0-a2b2-1959c93cca5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.80864742 0.81205093 0.80637842 0.80600025 0.80549603]\n",
      "Mean accuracy of model: 0.8077146098575569\n"
     ]
    }
   ],
   "source": [
    "gnb_ngrams = GaussianNB()\n",
    "\n",
    "cv_scores = cross_val_score(gnb_ngrams, X_train_bow_ng, y_train, cv=5)\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "\n",
    "gnb_ngrams_accuracy = np.mean(cv_scores)\n",
    "print(\"Mean accuracy of model:\", gnb_ngrams_accuracy)\n",
    "\n",
    "gnb_ngrams.fit(X_train_bow_ng, y_train) \n",
    "y_pred_gnb_ngrams = gnb_ngrams.predict(X_test_bow_ng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "796315d1-5be3-491f-9b65-041b4dfc2189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8099499375528331\n",
      "Recall: 0.8090148230311586\n",
      "F1 Score: 0.8087585127033047\n"
     ]
    }
   ],
   "source": [
    "precision_gnb_ngrams = precision_score(y_test, y_pred_gnb_ngrams, average='weighted')  # or 'macro', 'micro', etc.\n",
    "recall_gnb_ngrams = recall_score(y_test, y_pred_gnb_ngrams, average='weighted')\n",
    "f1_score_gnb_ngrams = f1_score(y_test, y_pred_gnb_ngrams, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Precision:\", precision_gnb_ngrams)\n",
    "print(\"Recall:\", recall_gnb_ngrams)\n",
    "print(\"F1 Score:\", f1_score_gnb_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "44d71ef9-8eb5-4cae-ac8a-b5b7bc182d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[4234  799]\n",
      " [1095 3789]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_gnb_ngrams = confusion_matrix(y_test, y_pred_gnb_ngrams)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix_gnb_ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77c7784",
   "metadata": {
    "id": "f77c7784"
   },
   "source": [
    "### `C.` Using TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7efd8b3f",
   "metadata": {
    "id": "7efd8b3f"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76e2d7ed",
   "metadata": {
    "id": "76e2d7ed"
   },
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf.fit_transform(X_train[:15000]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb7d1e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf = tfidf.transform(X_test[:15000]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7477bd41",
   "metadata": {},
   "source": [
    "#### 1.Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "36f0a58d-0386-4400-ae95-58a171381540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.77833333 0.778      0.78933333 0.76233333 0.77866667]\n",
      "Mean accuracy : 0.7773333333333333\n"
     ]
    }
   ],
   "source": [
    "rf_tfidf = RandomForestClassifier(n_estimators=300, min_samples_split = 5,\n",
    "                           min_samples_leaf = 2, max_features = 'log2',\n",
    "                           max_depth = 12, n_jobs = 6)\n",
    "\n",
    "cv_scores = cross_val_score(rf_tfidf, X_train_tfidf, y_train[:15000], cv=5)\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "\n",
    "rf_tfidf_accuracy = np.mean(cv_scores)\n",
    "print(\"Mean accuracy :\", rf_tfidf_accuracy)\n",
    "\n",
    "rf_tfidf.fit(X_train_tfidf, y_train[:15000]) \n",
    "y_pred_rf_tfidf = rf_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7ddd439d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7913413602578989\n",
      "Recall: 0.7875365533931633\n",
      "F1 Score: 0.7870776872336211\n"
     ]
    }
   ],
   "source": [
    "precision_rf_tfidf = precision_score(y_test, y_pred_rf_tfidf, average='weighted')  # or 'macro', 'micro', etc.\n",
    "recall_rf_tfidf = recall_score(y_test, y_pred_rf_tfidf, average='weighted')\n",
    "f1_score_rf_tfidf = f1_score(y_test, y_pred_rf_tfidf, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Precision:\", precision_rf_tfidf)\n",
    "print(\"Recall:\", recall_rf_tfidf)\n",
    "print(\"F1 Score:\", f1_score_rf_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "df82fdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3709 1324]\n",
      " [ 783 4101]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_rf_tfidf = confusion_matrix(y_test[:15000], y_pred_rf_tfidf)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix_rf_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2640941a",
   "metadata": {},
   "source": [
    "#### 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "00a3e15f-e375-445e-93a4-bb14a2df7abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.845      0.83933333 0.85966667 0.83733333 0.83733333]\n",
      "Mean accuracy: 0.8437333333333333\n"
     ]
    }
   ],
   "source": [
    "lr_tfidf = LogisticRegression(C=0.1,max_iter=100,\n",
    "                        n_jobs=12,penalty=\"l2\",\n",
    "                        solver='sag')\n",
    "\n",
    "cv_scores = cross_val_score(lr_tfidf, X_train_tfidf, y_train[:15000], cv=5)\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "\n",
    "lr_tfidf_accuracy = np.mean(cv_scores)\n",
    "print(\"Mean accuracy:\", lr_tfidf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d8217e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tfidf.fit(X_train_tfidf, y_train[:15000]) \n",
    "y_pred_lr_tfidf = lr_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f5f90a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8503632465487019\n",
      "Recall: 0.8485429061208026\n",
      "F1 Score: 0.8484412164295516\n"
     ]
    }
   ],
   "source": [
    "precision_lr_tfidf = precision_score(y_test, y_pred_lr_tfidf, average='weighted')  # or 'macro', 'micro', etc.\n",
    "recall_lr_tfidf = recall_score(y_test, y_pred_lr_tfidf, average='weighted')\n",
    "f1_score_lr_tfidf = f1_score(y_test, y_pred_lr_tfidf, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Precision:\", precision_lr_tfidf)\n",
    "print(\"Recall:\", recall_lr_tfidf)\n",
    "print(\"F1 Score:\", f1_score_lr_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5d7b5194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[4111  922]\n",
      " [ 580 4304]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_lr_tfidf = confusion_matrix(y_test[:15000], y_pred_lr_tfidf)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix_lr_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987efde3",
   "metadata": {},
   "source": [
    "#### 3. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9b8a181b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.72233333 0.713      0.73166667 0.705      0.71633333]\n",
      "Mean accuracy : 0.7176666666666667\n"
     ]
    }
   ],
   "source": [
    "dt_tfidf = DecisionTreeClassifier(min_samples_split=20, min_samples_leaf=10, max_depth=50,criterion='gini')\n",
    "\n",
    "cv_scores = cross_val_score(dt_tfidf, X_train_tfidf, y_train[:15000], cv=5)\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "\n",
    "dt_tfidf_accuracy = np.mean(cv_scores)\n",
    "print(\"Mean accuracy :\", dt_tfidf_accuracy)\n",
    "\n",
    "dt_tfidf.fit(X_train_tfidf, y_train[:15000]) \n",
    "y_pred_dt_tfidf = dt_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f7af36e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7186535522728146\n",
      "Recall: 0.7186649188262579\n",
      "F1 Score: 0.718657364644479\n"
     ]
    }
   ],
   "source": [
    "precision_dt_tfidf = precision_score(y_test, y_pred_dt_tfidf, average='weighted')  # or 'macro', 'micro', etc.\n",
    "recall_dt_tfidf = recall_score(y_test, y_pred_dt_tfidf, average='weighted')\n",
    "f1_score_dt_tfidf = f1_score(y_test, y_pred_dt_tfidf, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Precision:\", precision_dt_tfidf)\n",
    "print(\"Recall:\", recall_dt_tfidf)\n",
    "print(\"F1 Score:\", f1_score_dt_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "49d45c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3646 1387]\n",
      " [1403 3481]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_dt_tfidf = confusion_matrix(y_test[:15000], y_pred_dt_tfidf)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix_dt_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2999837",
   "metadata": {},
   "source": [
    "#### 4. Gussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ff4f6b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.622  0.629  0.6235 0.636  0.6235]\n",
      "Mean accuracy : 0.6268\n"
     ]
    }
   ],
   "source": [
    "gnb_tfidf = GaussianNB()\n",
    "\n",
    "cv_scores = cross_val_score(gnb_tfidf, X_train_tfidf[:10000], y_train[:10000], cv=5)\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "\n",
    "gnb_tfidf_accuracy = np.mean(cv_scores)\n",
    "print(\"Mean accuracy :\", gnb_tfidf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf4ee797",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_tfidf.fit(X_train_tfidf[:10000], y_train[:10000]) \n",
    "y_pred_gnb_tfidf = gnb_tfidf.predict(X_test_tfidf[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b153b256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6325333556082798\n",
      "Recall: 0.6320459816476757\n",
      "F1 Score: 0.6311451845236343\n"
     ]
    }
   ],
   "source": [
    "precision_gnb_tfidf = precision_score(y_test, y_pred_gnb_tfidf, average='weighted')  # or 'macro', 'micro', etc.\n",
    "recall_gnb_tfidf = recall_score(y_test, y_pred_gnb_tfidf, average='weighted')\n",
    "f1_score_gnb_tfidf = f1_score(y_test, y_pred_gnb_tfidf, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Precision:\", precision_gnb_tfidf)\n",
    "print(\"Recall:\", recall_gnb_tfidf)\n",
    "print(\"F1 Score:\", f1_score_gnb_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "36fa4f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3419 1614]\n",
      " [2035 2849]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_gnb_tfidf = confusion_matrix(y_test[:10000], y_pred_gnb_tfidf)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix_gnb_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4718e4af",
   "metadata": {},
   "source": [
    "# Using `Word2Vec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48abda2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec,KeyedVectors\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32da22d3-f8f0-4d52-b100-937f071f19e1",
   "metadata": {},
   "source": [
    "### Create Your Own Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f869f354",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    df['lemmatize_tokens'],\n",
    "    window=16,\n",
    "    min_count=2,\n",
    "    workers=12,\n",
    "    vector_size = 300,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f41dd1-3d09-402a-8aa4-26f3dd43661d",
   "metadata": {},
   "source": [
    "#### Build your vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea554edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(df['lemmatize_tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98e1b41-e8ac-422e-ba53-97a20fef3da0",
   "metadata": {},
   "source": [
    "#### Train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6a80960a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27739299, 29764055)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(df['lemmatize_tokens'], total_examples = model.corpus_count, epochs = model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbd2bc7-8069-437c-92ac-0fedd6c8f308",
   "metadata": {},
   "source": [
    "#### Convert each sentence into vector by taking the mean of all the vectors of the words , which are in the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ac95aeb-cb47-4fc2-95d9-a19b573dce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector(doc):\n",
    "    doc = [word for word in doc if word in model.wv.index_to_key]\n",
    "    return np.mean(model.wv[doc], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b022cab1-e60f-4657-902e-e8e4d5583245",
   "metadata": {},
   "source": [
    "#### Sample, how the vector of first sentence looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "697ccaa9-611c-402b-a713-2140abf3628f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.78147599e-01, -5.10223024e-02,  3.99951562e-02, -9.18036792e-03,\n",
       "       -3.79882842e-01,  2.67166793e-01, -5.22094190e-01, -1.31891429e+00,\n",
       "       -6.68720603e-02,  2.20211238e-01,  1.08216479e-01,  1.08081885e-01,\n",
       "        1.50446683e-01,  1.17426291e-01,  6.65958762e-01,  4.54275876e-01,\n",
       "       -3.76631543e-02,  2.26009876e-01,  6.31444827e-02,  6.09580316e-02,\n",
       "       -1.03368005e-02,  2.53046244e-01, -4.07715499e-01, -3.74304712e-01,\n",
       "       -2.12207243e-01,  1.74968094e-01,  7.83290416e-02, -1.23858273e-01,\n",
       "        5.82629396e-03,  8.27625021e-02, -2.24768415e-01, -2.06145868e-02,\n",
       "       -1.17274940e-01,  3.59415263e-01, -1.49576992e-01, -8.84710774e-02,\n",
       "        7.03948438e-02, -1.30212102e-02,  3.32835242e-02, -1.54258102e-01,\n",
       "        1.60328932e-02,  3.05197209e-01,  2.27816522e-01, -4.99388069e-01,\n",
       "        5.76038808e-02, -1.58826306e-01, -3.06345671e-01, -5.07605970e-01,\n",
       "        3.10602874e-01, -7.32449174e-01, -5.41511066e-02,  5.49884923e-02,\n",
       "        1.97481230e-01, -3.72081697e-01,  4.75068957e-01, -1.94775388e-01,\n",
       "       -2.74362355e-01, -1.41972765e-01,  3.01243752e-01,  1.43636569e-01,\n",
       "        1.64077401e-01,  2.52787769e-01, -1.18758949e-02, -6.68577850e-02,\n",
       "       -6.67096628e-03, -1.69952258e-01,  2.21143782e-01, -2.71174721e-02,\n",
       "        1.09871417e-01,  7.53130078e-01, -2.54798532e-01, -5.10790721e-02,\n",
       "       -3.61264139e-01, -4.10934947e-02, -4.41055804e-01,  8.31393301e-02,\n",
       "        4.05368507e-01, -5.15240610e-01,  1.31576315e-01, -1.89550072e-01,\n",
       "        3.03457499e-01,  2.80608356e-01, -5.29036522e-01,  3.99816722e-01,\n",
       "       -1.17515564e-01,  4.22647387e-01,  1.91551223e-01, -4.34051573e-01,\n",
       "        5.10325469e-02, -5.50581664e-02,  5.34784682e-02, -2.57345825e-01,\n",
       "       -3.19633454e-01, -1.88183695e-01, -5.62946975e-01, -4.16844375e-02,\n",
       "       -1.01935938e-01, -3.34962100e-01, -4.73565400e-01, -5.45785666e-01,\n",
       "       -2.42189303e-01,  3.02557275e-02, -2.87219256e-01,  2.09234372e-01,\n",
       "        3.92672092e-01,  7.90978074e-02, -1.28788903e-01,  3.71278673e-01,\n",
       "       -2.23749474e-01,  2.84467414e-02, -8.95200595e-02,  7.52069652e-02,\n",
       "        2.68855363e-01,  9.19765607e-02,  2.70184070e-01, -3.35920960e-01,\n",
       "        2.22675756e-01, -6.57933295e-01, -4.21310574e-01, -2.72389054e-01,\n",
       "        2.19936833e-01,  6.08938277e-01, -1.67900294e-01,  2.13956296e-01,\n",
       "       -1.56280603e-02,  2.26247549e-01,  1.45917013e-03, -4.77967173e-01,\n",
       "        3.80141348e-01, -1.14196673e-01,  3.42610367e-02, -5.16026258e-01,\n",
       "        1.68675371e-02, -2.00407952e-02, -1.95043664e-02,  7.25705504e-01,\n",
       "       -1.95210457e-01,  6.66369498e-02,  1.01734936e-01,  1.31338090e-01,\n",
       "        1.26366466e-01, -3.42826955e-02, -1.66677907e-01, -1.67224437e-01,\n",
       "       -4.06110585e-01,  2.29120061e-01,  1.00589715e-01,  1.34584233e-01,\n",
       "       -1.11374445e-01, -5.89079261e-01,  3.39692205e-01,  1.82862490e-01,\n",
       "        1.05669610e-01, -6.25710338e-02, -3.79366696e-01,  3.63537371e-01,\n",
       "        1.72316924e-01,  4.52065580e-02, -2.63337404e-01, -6.84444726e-01,\n",
       "       -3.37431252e-01, -4.22295704e-02,  1.22154072e-01,  1.77001193e-01,\n",
       "        1.61252528e-01, -3.11927907e-02,  8.23918879e-02,  8.07278305e-02,\n",
       "       -2.58102149e-01, -5.18945158e-01, -2.29610652e-01, -1.08592868e-01,\n",
       "       -2.12184280e-01, -1.70284659e-01,  3.20183367e-01,  5.62082417e-02,\n",
       "       -3.94955069e-01,  3.28801006e-01,  3.34800094e-01,  2.80187696e-01,\n",
       "        6.29942179e-01, -4.81639594e-01, -2.76149362e-01, -1.78278551e-01,\n",
       "       -6.65259212e-02,  2.61841208e-01,  2.93771680e-02, -3.36714476e-01,\n",
       "        9.37388744e-03,  1.35427530e-04,  4.72980291e-01, -1.82154074e-01,\n",
       "       -4.65039581e-01,  2.24234894e-01, -1.50524572e-01,  6.37457892e-03,\n",
       "       -2.27063656e-01, -1.74412414e-01, -3.83861549e-02, -4.41831976e-01,\n",
       "        3.91415626e-01, -1.30281135e-01,  6.00856602e-01, -2.27559149e-01,\n",
       "        3.87457907e-01, -2.74409980e-01, -2.15957761e-01, -3.01212877e-01,\n",
       "       -1.59990281e-01,  3.80316198e-01,  7.76280239e-02,  1.84198514e-01,\n",
       "        5.14010750e-02,  2.64833719e-01,  3.36185098e-01,  2.82566994e-01,\n",
       "       -3.37644100e-01,  2.04216409e-02,  6.09778538e-02,  1.58022612e-01,\n",
       "        1.39290556e-01,  1.99078191e-02,  1.56840965e-01,  6.46639988e-02,\n",
       "       -2.95112543e-02,  9.51448262e-01, -2.49319851e-01,  3.44833821e-01,\n",
       "        1.79636717e-01,  2.30495125e-01, -2.31929526e-01, -3.91944908e-02,\n",
       "       -1.17497452e-01, -2.74799645e-01,  3.33920807e-01, -2.88993478e-01,\n",
       "        8.51923018e-04,  3.53078544e-01, -2.35393137e-01, -9.06784534e-02,\n",
       "       -1.54334992e-01,  1.56505853e-01,  2.27863774e-01,  1.55666079e-02,\n",
       "       -2.29698509e-01,  1.93558231e-01,  4.69245732e-01, -2.92987585e-01,\n",
       "       -1.49243400e-01, -3.54650058e-02,  2.38120526e-01,  2.37160474e-01,\n",
       "       -6.10811636e-02,  6.76721573e-01,  4.18386161e-01,  1.38163313e-01,\n",
       "       -1.17519677e-01,  3.35902214e-01,  4.40703109e-02, -1.78723976e-01,\n",
       "       -2.65025616e-01,  1.73898309e-01, -3.75443310e-01, -2.61571467e-01,\n",
       "        5.88379353e-02,  2.35429913e-01, -2.90587097e-01,  3.40775311e-01,\n",
       "        2.24265203e-01, -1.53525129e-01, -4.49783057e-01, -9.34407935e-02,\n",
       "       -1.40343189e-01, -9.22987610e-02,  5.98667800e-01,  5.88518023e-01,\n",
       "       -1.73087008e-02,  1.21586639e-02,  1.33458376e-01, -6.09142892e-02,\n",
       "        1.54356450e-01, -8.79774690e-02, -6.71615405e-03, -5.68984523e-02,\n",
       "        7.84789026e-02,  4.97923531e-02,  4.42802101e-01, -2.33608127e-01,\n",
       "        2.08847374e-01,  4.61674184e-01,  2.52733584e-02, -6.74455836e-02,\n",
       "       -9.59027559e-02,  1.05615199e-01,  3.80704820e-01, -1.01959296e-01,\n",
       "        1.64074033e-01, -1.34028811e-02,  1.43131778e-01,  1.86575010e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_vector(df['lemmatize_tokens'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84d63b0-65dd-48e6-8c9d-b208bbac2908",
   "metadata": {},
   "source": [
    "### Convert each sentence into a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f6c9f808-5685-4c05-add5-aec6cf2f347f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/49582 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49582/49582 [13:10<00:00, 62.69it/s] \n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for doc in tqdm(df['lemmatize_tokens'].values):\n",
    "    X.append(document_vector(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a23fb96-4805-4e90-9bb6-27f49c64bced",
   "metadata": {},
   "source": [
    "#### We will get sparse matrix of each sentence so convert them into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "87b41c92-5b11-431a-bfd7-ab9ba57a6bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa65310a-b79b-40ba-887d-e342bee0a2f4",
   "metadata": {},
   "source": [
    "### Convert the value of column `Y` into zero and one as they are positive and negative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e3280661-5419-4b67-966a-6741fb78dbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38b7cfd-458a-47b3-93f3-76fc9b0d1232",
   "metadata": {},
   "source": [
    "### Split our dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3398ef13-8b5b-4dd2-8ddb-85bf9e3ef874",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f6cb63-3dba-4b5e-b01b-f76bef0b71d1",
   "metadata": {},
   "source": [
    "# Now Apply Machine Learning Algorithm on data using `Word2Vec`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec94212-4f1a-4ce5-bcff-9ecc5a846fc4",
   "metadata": {},
   "source": [
    "#### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "697d1824-91b7-479e-b5d3-57e45194a7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'sag', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'solver': ['lbfgs', 'sag', 'liblinear']}\n",
    "\n",
    "grid_search = RandomizedSearchCV(lr, param_grid, scoring='accuracy', n_jobs = -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best hyperparameters:\", best_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1b5c5248-206c-4029-9d60-fbfb4b8cc6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.87898651 0.88087735 0.87747384 0.87936468 0.88352452]\n",
      "Mean accuracy of model: 0.8800453800579856\n"
     ]
    }
   ],
   "source": [
    "lr_w2v = LogisticRegression(C=1,max_iter=100,multi_class=\"auto\", \n",
    "                        n_jobs=12,penalty=\"l2\",\n",
    "                        solver='sag')\n",
    "\n",
    "cv_scores = cross_val_score(lr_w2v, X_train, y_train, cv=5)\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "\n",
    "lr_w2v_accuracy = np.mean(cv_scores)\n",
    "print(\"Mean accuracy of model:\", lr_w2v_accuracy)\n",
    "\n",
    "lr_w2v.fit(X_train, y_train)\n",
    "y_pred_lr_w2v = lr_w2v.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a0e4a7fc-fe8b-4e44-b142-1d3dcdb913c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8769281948862215\n",
      "Recall: 0.8765755772915196\n",
      "F1 Score: 0.8765771585809969\n"
     ]
    }
   ],
   "source": [
    "precision_lr_w2v = precision_score(y_test, y_pred_lr_w2v, average='weighted')  # or 'macro', 'micro', etc.\n",
    "recall_lr_w2v = recall_score(y_test, y_pred_lr_w2v, average='weighted')\n",
    "f1_score_lr_w2v = f1_score(y_test, y_pred_lr_w2v, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Precision:\", precision_lr_w2v)\n",
    "print(\"Recall:\", recall_lr_w2v)\n",
    "print(\"F1 Score:\", f1_score_lr_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f44a651-e4a5-4cbe-aad3-67266cc5efd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[4351  682]\n",
      " [ 542 4342]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_lr_w2v = confusion_matrix(y_test, y_pred_lr_w2v)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix_lr_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3161f2fb",
   "metadata": {},
   "source": [
    "#### 2. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "48d7e857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 10, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'kernel': ['linear', 'rbf'],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "grid_search = RandomizedSearchCV(svm, param_grid, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best hyperparameters:\", best_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "71e49a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.87949073 0.87898651 0.87797807 0.87961679 0.88554141]\n",
      "Mean accuracy: 0.8803227026345646\n"
     ]
    }
   ],
   "source": [
    "svm_w2v = SVC(C=10, decision_function_shape=\"ovr\", kernel=\"rbf\")\n",
    "\n",
    "cv_scores = cross_val_score(svm_w2v, X_train, y_train, cv=5)\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "\n",
    "svm_w2v_accuracy = np.mean(cv_scores)\n",
    "print(\"Mean accuracy:\", svm_w2v_accuracy)\n",
    "\n",
    "svm_w2v.fit(X_train, y_train)\n",
    "y_pred_svm_w2v = svm_w2v.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7fbab8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.885235523003334\n",
      "Recall: 0.8851467177573863\n",
      "F1 Score: 0.88515309461305\n"
     ]
    }
   ],
   "source": [
    "precision_svm_w2v = precision_score(y_test, y_pred_svm_w2v, average='weighted')  # or 'macro', 'micro', etc.\n",
    "recall_svm_w2v = recall_score(y_test, y_pred_svm_w2v, average='weighted')\n",
    "f1_score_svm_w2v = f1_score(y_test, y_pred_svm_w2v, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Precision:\", precision_svm_w2v)\n",
    "print(\"Recall:\", recall_svm_w2v)\n",
    "print(\"F1 Score:\", f1_score_svm_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c608e58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[4431  602]\n",
      " [ 537 4347]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_svm_w2v = confusion_matrix(y_test, y_pred_svm_w2v)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix_svm_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59042bb3",
   "metadata": {},
   "source": [
    "#### 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "39d9a80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 12}\n"
     ]
    }
   ],
   "source": [
    "param_distributions = {\n",
    "    'n_estimators': [100, 200, 300], \n",
    "    'max_depth': [4, 8, 12],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "grid_search = RandomizedSearchCV(estimator=RandomForestClassifier(), param_distributions=param_distributions, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "da1bf2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.84898525 0.8411698  0.84394302 0.84469936 0.84646414]\n",
      "Mean accuracy: 0.8450523131224001\n"
     ]
    }
   ],
   "source": [
    "rf_w2v = RandomForestClassifier(\n",
    "    criterion='gini', max_depth=12, \n",
    "    max_features = \"log2\", min_samples_leaf=1,\n",
    "    n_estimators=300,n_jobs=-1,\n",
    "    min_samples_split= 2\n",
    ")\n",
    "\n",
    "cv_scores = cross_val_score(rf_w2v, X_train, y_train, cv=5)\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "\n",
    "rf_w2v_accuracy = np.mean(cv_scores)\n",
    "print(\"Mean accuracy:\", rf_w2v_accuracy)\n",
    "\n",
    "rf_w2v.fit(X_train, y_train)\n",
    "y_pred_rf_w2v = rf_w2v.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eedf21ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.84453820776827\n",
      "Recall: 0.8437027326812544\n",
      "F1 Score: 0.843674105389934\n"
     ]
    }
   ],
   "source": [
    "precision_rf_w2v = precision_score(y_test, y_pred_rf_w2v, average='weighted')  # or 'macro', 'micro', etc.\n",
    "recall_rf_w2v = recall_score(y_test, y_pred_rf_w2v, average='weighted')\n",
    "f1_score_rf_w2v = f1_score(y_test, y_pred_rf_w2v, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Precision:\", precision_rf_w2v)\n",
    "print(\"Recall:\", recall_rf_w2v)\n",
    "print(\"F1 Score:\", f1_score_rf_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "03e83694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[4144  889]\n",
      " [ 661 4223]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_rf_w2v = confusion_matrix(y_test, y_pred_rf_w2v)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix_rf_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea919a78",
   "metadata": {},
   "source": [
    "#### 4. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aaf02a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 10],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "grid_search = RandomizedSearchCV(estimator=dt, param_distributions=param_grid, scoring='accuracy', n_jobs=8)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_dt = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "478e7ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.74763646 0.7475104  0.75343502 0.74209    0.74826673]\n",
      "Mean accuracy: 0.7477877221732007\n"
     ]
    }
   ],
   "source": [
    "dt_w2v = DecisionTreeClassifier(min_samples_split=5, min_samples_leaf=1,\n",
    "                                max_depth=10,max_features='sqrt', criterion='gini')\n",
    "\n",
    "cv_scores = cross_val_score(dt_w2v, X_train, y_train, cv=5)\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "\n",
    "dt_w2v_accuracy = np.mean(cv_scores)\n",
    "print(\"Mean accuracy:\", dt_w2v_accuracy)\n",
    "\n",
    "dt_w2v.fit(X_train, y_train)\n",
    "y_pred_dt_w2v = dt_w2v.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ab31acd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7651056913974552\n",
      "Recall: 0.7646465665019663\n",
      "F1 Score: 0.7646351944309472\n"
     ]
    }
   ],
   "source": [
    "precision_dt_w2v = precision_score(y_test, y_pred_dt_w2v, average='weighted')  # or 'macro', 'micro', etc.\n",
    "recall_dt_w2v = recall_score(y_test, y_pred_dt_w2v, average='weighted')\n",
    "f1_score_dt_w2v = f1_score(y_test, y_pred_dt_w2v, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Precision:\", precision_dt_w2v)\n",
    "print(\"Recall:\", recall_dt_w2v)\n",
    "print(\"F1 Score:\", f1_score_dt_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b7a46365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3778 1255]\n",
      " [1079 3805]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_dt_w2v = confusion_matrix(y_test, y_pred_dt_w2v)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix_dt_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c28fa9",
   "metadata": {},
   "source": [
    "#### 5. Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0397da7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.80247069 0.79528552 0.79364679 0.79036934 0.79679818]\n",
      "Mean accuracy of model: 0.7957141056346905\n"
     ]
    }
   ],
   "source": [
    "gnb_w2v = GaussianNB()\n",
    "\n",
    "cv_scores = cross_val_score(gnb_w2v, X_train, y_train, cv=5)\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "\n",
    "gnb_w2v_accuracy = np.mean(cv_scores)\n",
    "print(\"Mean accuracy of model:\", gnb_w2v_accuracy)\n",
    "\n",
    "gnb_w2v.fit(X_train, y_train) \n",
    "y_pred_gnb_w2v = gnb_w2v.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1f0e2308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7913264018180213\n",
      "Recall: 0.7910658465261672\n",
      "F1 Score: 0.7910724323978559\n"
     ]
    }
   ],
   "source": [
    "precision_gnb_w2v = precision_score(y_test, y_pred_gnb_w2v, average='weighted')  # or 'macro', 'micro', etc.\n",
    "recall_gnb_w2v = recall_score(y_test, y_pred_gnb_w2v, average='weighted')\n",
    "f1_score_gnb_w2v = f1_score(y_test, y_pred_gnb_w2v, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Precision:\", precision_gnb_w2v)\n",
    "print(\"Recall:\", recall_gnb_w2v)\n",
    "print(\"F1 Score:\", f1_score_gnb_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "12bb7f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3778 1255]\n",
      " [1079 3805]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_gnb_w2v = confusion_matrix(y_test, y_pred_dt_w2v)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix_gnb_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e12633",
   "metadata": {},
   "source": [
    "### We have all the famous algorithm and we got best accuracy with `LOGISITC REGRESSION` by using all diffrent techniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aa3ced67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision lr ngrams: 0.8852382837575559\n",
      "Recall lr ngrams: 0.8847433699707573\n",
      "F1 Score lr ngrams: 0.8847398471082164\n",
      "Confusion Matrix lr ngrams :\n",
      " [[4378  655]\n",
      " [ 488 4396]]\n",
      "**************************************************\n",
      "Precision lr w2v: 0.8769281948862215\n",
      "Recall lr w2v: 0.8765755772915196\n",
      "F1 Score lr w2v: 0.8765771585809969\n",
      "Confusion Matrix lr w2v :\n",
      " [[4351  682]\n",
      " [ 542 4342]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision lr ngrams:\", precision_lr_ngrams)\n",
    "print(\"Recall lr ngrams:\", recall_lr_ngrams)\n",
    "print(\"F1 Score lr ngrams:\", f1_score_lr_ngrams)\n",
    "print(\"Confusion Matrix lr ngrams :\\n\", confusion_matrix_lr_ngrams)\n",
    "\n",
    "print('*'*50)\n",
    "\n",
    "print(\"Precision lr w2v:\", precision_lr_w2v)\n",
    "print(\"Recall lr w2v:\", recall_lr_w2v)\n",
    "print(\"F1 Score lr w2v:\", f1_score_lr_w2v)\n",
    "print(\"Confusion Matrix lr w2v :\\n\", confusion_matrix_lr_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c5f4a7-dce2-4f25-939f-d6b5be3fd368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to choose a model which have low type one error ,\n",
    "# means how many negative reviews is predicted as positive by our model"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
